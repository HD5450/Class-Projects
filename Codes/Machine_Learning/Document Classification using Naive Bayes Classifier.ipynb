{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Document Classification using Naive Bayes Classifier.ipynb","provenance":[{"file_id":"1mE7PrT83eOP7UPE1wbL9Vj64EChkZknA","timestamp":1537298367625}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"9JUWkOJJ8S59"},"source":["# **Session 7: Probability and Statistics for AI & Machine Learning II**\n","## Document Classification using Naive Bayes Classifier.\n","\n","## PY599 (Fall 2018): Applied Artificial Intelligence\n","## NC State University\n","###Dr. Behnam Kia\n","### https://appliedai.wordpress.ncsu.edu/\n","\n","\n","**Disclaimer**: Please note that these codes are simplified version of the algorithms, and they may not give the best, or expected performance that you could possibly get from these algorithms. The aim of this notebook is to help you understand the basics and the essence of these algorithms, and experiment with them. These basic codes are not deployment-ready or free-of-errors for real-world applications. To learn more about these algorithms please refer to text books that specifically study these algorithms, or contact me. - Behnam Kia"]},{"cell_type":"markdown","metadata":{"id":"wq1U3LBU7hQ-"},"source":["# Dataset "]},{"cell_type":"markdown","metadata":{"id":"2InEE1wy7B6U"},"source":["Method 1: You can download dataset from Keras. In this dataset the words are replaced by a unique number. According to Keras' website, \"Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, words are indexed by overall frequency in the dataset, so that for instance the integer \"3\" encodes the 3rd most frequent word in the data. This allows for quick filtering operations such as: \"only consider the top 10,000 most common words, but eliminate the top 20 most common words\".\n","\n","As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\"\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Q2aenG6M6JZA"},"source":["# Collaboration: Richard Watson, Mountain Chan\n","import collections\n","import math\n","from keras.datasets import imdb\n","(x_train, y_train), (x_test, y_test) = imdb.load_data(path=\"imdb.npz\",\n","                                                      num_words=None,\n","                                                      skip_top=0,\n","                                                      maxlen=None,\n","                                                      seed=113,\n","                                                      start_char=1,\n","                                                      oov_char=2,\n","                                                      index_from=3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m0gCnTMK6ciV","executionInfo":{"status":"ok","timestamp":1537993942484,"user_tz":240,"elapsed":11624,"user":{"displayName":"Mountain Chan","photoUrl":"","userId":"06751548981326338197"}},"outputId":"3940b2ed-e558-49cc-d4dd-fcd3f2aac0fe","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def dict(x_train, y_train):\n","  # Create positive review dict\n","  cnt_pos = collections.Counter()\n","  for review in range(len(x_train)):\n","    if y_train[review] == 1:\n","      for word in range(len(x_train[review])):\n","        cnt_pos[x_train[review][word]] += 1\n","  \n","  # Create negative review dict\n","  cnt_neg = collections.Counter()\n","  for review in range(len(x_train)):\n","    if y_train[review] == 0:\n","      for word in range(len(x_train[review])):\n","        cnt_neg[x_train[review][word]] += 1\n","  \n","  # Find sum of all words in positive review\n","  sum_pos = sum(cnt_pos.values())\n","  # Find sum of all words in negative review\n","  sum_neg = sum(cnt_neg.values())\n","  \n","  return cnt_pos, cnt_neg, sum_pos, sum_neg      \n","\n","def naive_bayes(review, cnt_pos, cnt_neg, sum_pos, sum_neg):\n","  pos_prob = 0\n","  neg_prob = 0\n","  vocab = 10000\n","\n","  # Create dict per review\n","  cnt = collections.Counter()\n","  \n","  # Get keys for all words in review\n","  reviewKey = cnt.keys()\n","  \n","  for word in review:\n","    cnt[word] += 1\n","  \n","  # Get log probability for positive review\n","  for word in reviewKey:\n","    pos_prob += cnt[word] * math.log((cnt_pos[word] + 1)/(sum_pos + vocab))\n","  \n","  # Get log probability for negative review\n","  for word in reviewKey:\n","    neg_prob += cnt[word] * math.log((cnt_neg[word] + 1)/(sum_neg + vocab))\n","    \n","  return pos_prob > neg_prob\n","\n","correct = 0\n","cnt_pos, cnt_neg, sum_pos, sum_neg = dict(x_train, y_train)\n","for review in range (len(x_test)):\n","  correct += naive_bayes(x_test[review], cnt_pos, cnt_neg, sum_pos, sum_neg) == y_test[review]\n","print(correct/len(x_test))  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.81272\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lohT1Yla6ehU"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c2fuzlae7ooQ"},"source":["Method 2: You can download the original dataset with readible reviews. Please go to: \n","http://ai.stanford.edu/~amaas/data/sentiment/\n","\n","and download \"Large Movie Review Dataset v1.0.\"\n","\n","There are many different methods to upload dataset to colab. \n","One method is to download the dataset to your local computer, then upload it to colab and then unzip it. Please see the code below:"]},{"cell_type":"code","metadata":{"id":"ebsg_pa96hhN"},"source":["from google.colab import files\n","\n","uploaded = files.upload()\n","!tar xzvf aclImdb_v1.tar.gz >/dev/null\n"],"execution_count":null,"outputs":[]}]}