{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Redesign MNIST classifier.ipynb","provenance":[{"file_id":"15Pkv_mU1g7yJaOHcT__pCooSMWU5cKMn","timestamp":1540865097360}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Id1ZYbfNTbde"},"source":["# import modules\n","import numpy as np\n","from random import choice\n","seed = 42 # goto number\n","np.random.seed(seed)\n","\n","from keras.datasets import mnist\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.utils import np_utils\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbRbl4VtUTnq","executionInfo":{"status":"ok","timestamp":1540865286066,"user_tz":240,"elapsed":4269,"user":{"displayName":"Mountain Chan","photoUrl":"","userId":"06751548981326338197"}},"outputId":"18a1fe2f-4c97-451b-8291-5bb87504f9c2","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# load data and split it into training, dev, and test sets\n","(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n","X_train, X_dev, Y_train, Y_dev = train_test_split(X_train, Y_train, test_size=1/6, random_state=seed)\n","\n","# preprocess data\n","num_of_pixels = X_train.shape[1]*X_train.shape[2]\n","X_train = X_train.reshape(X_train.shape[0], num_of_pixels).astype('float32')\n","X_dev = X_dev.reshape(X_dev.shape[0], num_of_pixels).astype('float32')\n","X_test = X_test.reshape(X_test.shape[0], num_of_pixels).astype('float32')\n","X_train = X_train / 255\n","X_dev = X_dev / 255\n","X_test = X_test / 255\n","\n","Y_train = np_utils.to_categorical(Y_train)\n","Y_dev = np_utils.to_categorical(Y_dev)\n","Y_test = np_utils.to_categorical(Y_test)\n","num_classes = Y_test.shape[1]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 2s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Mgy0y16SUZow","executionInfo":{"status":"ok","timestamp":1540865287309,"user_tz":240,"elapsed":443,"user":{"displayName":"Mountain Chan","photoUrl":"","userId":"06751548981326338197"}},"outputId":"1c2c0dd5-9e95-407e-e8e0-050a3b413dd4","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# create hyperparameter grid\n","\n","batch_size = 50\n","epochs = 10\n","neurons = np.arange(30,151)\n","layers = np.arange(2,5)\n","loss = ['categorical_crossentropy','categorical_hinge']\n","opt = ['sgd','rmsprop','adagrad','adadelta','adam','adamax','nadam']\n","act = ['relu','sigmoid']\n","number_of_models = len(neurons)*len(layers)*len(loss)*len(opt)*len(act)\n","\n","number_of_models # way too many to test, so we will take random subset of initial population to try"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10164"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"UNsc0WD2UdcI"},"source":["# create initial population\n","pop_size = int(number_of_models / 100)\n","ch = np.random.choice # here for abbrev. purposes\n","pop = [(ch(neurons),ch(layers),ch(loss),ch(opt),ch(act)) for i in range(pop_size)]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"INU9hkAcuxXB"},"source":["# Find most fit model using Genetic Algorithm\n","\n","# translate hyperparameter tuple to actual model\n","def model_from_hyper(hyperparameters):\n","  neurons,layers,loss,opt,act = hyperparameters\n","  \n","  # first split neurons-num_classes up among layers-1\n","  layers -= 1\n","  neurons -= num_classes - layers # subtract by layers now for zero check later\n","  seperator = [0]*neurons + [1]*(layers-1)\n","  np.random.shuffle(seperator)\n","  neuron_list = [0]*layers\n","  i = 0\n","  for n in seperator:\n","    if not n:\n","      neuron_list[i] += 1\n","    else:\n","      i += 1\n","  neuron_list = np.sort(neuron_list)[::-1]\n","  \n","  # make sure there is at least 1 neuron per layer\n","  model = Sequential()\n","  model.add(Dense(neuron_list[0]+1,input_dim=num_of_pixels,activation=act))\n","  for l in range(1,layers-1):\n","    model.add(Dense(neuron_list[l]+1,activation=act))\n","  model.add(Dense(num_classes, activation='softmax'))\n","  model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n","  \n","  return model\n","\n","# here to save time\n","acc_dict = {}\n","\n","# we will use accuracy as our fitness metric\n","def fitness(individual):\n","  # get pre-saved accuracy if available\n","  acc = acc_dict.get(individual)\n","  \n","  if not acc:\n","    model = model_from_hyper(individual)\n","    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n","  \n","    # save accuracy\n","    acc = model.evaluate(X_dev, Y_dev, verbose=0)[1]\n","    acc_dict[individual] = acc\n","  \n","  return acc\n","\n","# child will have the 'average' hyperparameter of parents\n","def crossover(p1,p2):\n","  neurons = int((p1[0]+p2[0])/2)\n","  layers = int((p1[1]+p2[1])/2)\n","  loss = np.random.choice((p1[2],p2[2]))\n","  opt = np.random.choice((p1[3],p2[3]))\n","  act = np.random.choice((p1[4],p2[4]))\n","  \n","  return (neurons, layers, loss, opt, act)\n","\n","# adds 'random' noise to hyperparameters of child population\n","def mutation(population, child_indices, mutation_frac):\n","  child_pop_size = len(child_indices)\n","  np.random.shuffle(child_indices)\n","  \n","  # mutate fraction of children\n","  for i in child_indices[:int(child_pop_size*mutation_frac)]:\n","    new_neurons = int(population[i][0] + np.random.random())\n","    new_layers = int(population[i][1] + np.random.random())\n","    new_loss = population[i][2]\n","    if np.random.random() > 0.5:\n","      new_loss = loss[len(loss) - loss.index(new_loss) - 1]\n","    new_opt = population[i][3]\n","    if np.random.random() > 0.5:\n","      new_opt = opt[len(opt) - opt.index(new_opt) - 1]\n","    new_act = population[i][4]\n","    if np.random.random() > 0.5:\n","      new_act = act[len(act) - act.index(new_act) - 1]\n","    population[i] = (new_neurons,new_layers,new_loss,new_opt,new_act)\n","      \n","  return population\n","\n","# the fun part\n","def GA(population, tournament_size=10, max_generation_num=10,\n","       mutation_frac=0.25, survivers=.9):\n","  for i in range(max_generation_num):\n","    # 90% of the population survives\n","    indices = np.arange(pop_size)\n","    np.random.shuffle(indices)\n","    indices = indices[:int(pop_size*(1-survivers))]\n","    for j in indices:\n","      tournament = [choice(population) for i in range(tournament_size)]\n","      p1 = max(tournament, key=fitness)\n","      \n","      tournament = [choice(population) for i in range(tournament_size)]\n","      p2 = max(tournament, key=fitness)\n","      \n","      population[j] = crossover(p1,p2) #replace dead individual\n","    # only mutate new individuals\n","    population = mutation(population, indices, mutation_frac)\n","  return population\n","\n","king_hyperparameters = max(GA(pop), key=fitness)\n","king = model_from_hyper(king_hyperparameters)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfLtvEtp0MWn","executionInfo":{"status":"ok","timestamp":1540860949113,"user_tz":240,"elapsed":55863,"user":{"displayName":"Richard Watson","photoUrl":"","userId":"14389530188112868238"}},"outputId":"b3580273-16db-4978-a377-8b31f9217db9","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["# test the king\n","king.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n","scores = king.evaluate(X_test, Y_test, verbose=0)\n","print(\"Accuracy of the King: %.2f%%\" % (scores[1]*100))\n","print(\"Hyperparameters of the King: \", king_hyperparameters)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Accuracy of the King: 97.68%\n","Hyperparameters of the King:  (128, 2, 'categorical_crossentropy', 'adam', 'relu')\n"],"name":"stdout"}]}]}