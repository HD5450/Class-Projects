{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Full Polynomial Fitting.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"yw21zASHuPJI","colab_type":"code","colab":{}},"cell_type":"code","source":["import sys\n","import time\n","import datetime\n","import os\n","import math\n","import numpy as np\n","import matplotlib as mpl\n","from matplotlib import pyplot as plt\n","from matplotlib import rc\n","from matplotlib.pyplot import legend\n","\n","plt.rcParams['figure.figsize'] = [20, 15]\n","\n","\n","# From Handbook of Mathematical Functions, formula 7.1.26.\n","def erf(x):\n","    # save the sign of x\n","    sign = 1 if x >= 0 else -1\n","    x = abs(x)\n","\n","    # constants\n","    a1 =  0.254829592\n","    a2 = -0.284496736\n","    a3 =  1.421413741\n","    a4 = -1.453152027\n","    a5 =  1.061405429\n","    p  =  0.3275911\n","\n","    # A&S formula 7.1.26\n","    t = 1.0/(1.0 + p*x)\n","    y = 1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*math.exp(-x*x)\n","    return sign*y # erf(-x) = -erf(x)\n","\n","def polynomial_fitted_y_values(x, w):\n","    x = [x ** j for j in np.arange(0, w.size)]\n","    wTx = w[:, np.newaxis].T.dot(x).T\n","    return wTx[:, 0]\n","\n","def least_squares(M, x, t):\n","    x = np.array([x ** j for j in np.arange(0, M + 1)])\n","    return np.linalg.solve(x.dot(x.T), x.dot(t))\n","\n","def rmse(predictions, targets):\n","    return np.sqrt(((predictions - targets) ** 2).mean())\n","\n","def mean_absolute_error(predictions, targets):\n","  return np.absolute(predictions - targets).mean()\n","\n","def absolute_error(predictions, targets):\n","  return np.absolute(predictions - targets).sum()\n","  \n","def main():\n","  \n","    x = np.linspace(-10, 10, 21)\n","    \n","    t =  np.array([erf(xVal) for xVal in x])\n","    xs = np.linspace(-10, 10, 21)\n","    \n","    t_ideal = np.array([erf(xVal) for xVal in xs])\n","    \n","    l2_diff = []\n","    rms_diff = []\n","    mae_diff = []\n","    abs_errors = []\n","\n","    M = np.arange(0, 10).reshape(-1)\n","    fig_row = np.ceil(M.shape[0] / 2)\n","    fig_col = np.ceil(len(M) / fig_row)\n","    fig = plt.figure()\n","    for i, m in enumerate(M):\n","        w = least_squares(m, x, t)\n","        fig.add_subplot(fig_row, fig_col, i + 1)\n","        plt.plot(x, t, 'b.', label='Training data')\n","        plt.plot(xs, t_ideal, 'g-', label='f(x) = erf(x)')\n","        # Compute Various errors here\n","        l2_norm = np.linalg.norm((t_ideal - polynomial_fitted_y_values(xs, w)), 2)\n","        rms_error = rmse(polynomial_fitted_y_values(xs, w), t_ideal)\n","        mae = mean_absolute_error(polynomial_fitted_y_values(xs, w), t_ideal)\n","        abs_error = absolute_error(polynomial_fitted_y_values(xs, w), t_ideal)\n","        \n","        rms_diff.append(rms_error)\n","        mae_diff.append(mae)\n","        abs_errors.append(abs_error)\n","        \n","        plt.plot(xs, polynomial_fitted_y_values(xs, w), 'y-', label='Polynomial Curve fitting')\n","        plt.legend()\n","        plt.title('M = {0}'.format(m))\n","        plt.xlim(-10, 10)\n","        plt.ylim(-6.5, 6.5)\n","\n","    fig, ax = plt.subplots(figsize=(10, 5))   \n","    ax.plot(np.arange(0, 10), abs_errors, marker='o', label='Absolute Maximum Error')\n","    ax.plot(np.arange(0, 10), rms_diff, marker=\"*\", label='RMSE')\n","    ax.set_title('Degree vs. RMS Error and Absolute Maximum Error')\n","    ax.set_xlabel('n = Degree')\n","    ax.set_ylabel('Error')\n","    plt.legend()\n","\n","    plt.yticks(np.arange(-10,10, 2))\n","    plt.xticks(np.arange(0,10,1))\n","    plt.show()\n","\n","if __name__ == '__main__':\n","  main()"],"execution_count":0,"outputs":[]}]}